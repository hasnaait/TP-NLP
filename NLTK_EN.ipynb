{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP_NLTK\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (4.61.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import  word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import  WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte = \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a way which had not happened before.\"\"\"\n",
    "text = texte.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences is 6\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(text)\n",
    "print(\"The number of sentences is\", len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning from punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = \"\".join([char for char in text if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens is 130\n",
      "\n",
      " The average number of tokens per sentence is 22\n",
      "\n",
      " The number of unique tokens are 83\n",
      "\n",
      " Words: ['perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'alkhwarizmi', 'namely', 'the', 'beginnings', 'of', 'algebra', 'it', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', 'it', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', 'algebra', 'was', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', 'numbers', 'irrational', 'numbers', 'geometrical', 'magnitudes', 'etc', 'to', 'all', 'be', 'treated', 'as', 'algebraic', 'objects', 'it', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', 'another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before']\n",
      "\n",
      " Unique Words: {'magnitudes', 'how', 'ideas', 'unifying', 'concept', 'future', 'understand', 'allowed', 'so', 'mathematics', 'most', 'beginnings', 'had', 'in', 'objects', 'one', 'not', 'this', 'made', 'the', 'away', 'development', 'existed', 'revolutionary', 'gave', 'etc', 'all', 'just', 'at', 'itself', 'arabic', 'a', 'algebra', 'significant', 'that', 'much', 'by', 'alkhwarizmi', 'as', 'another', 'for', 'rational', 'work', 'provided', 'applied', 'advances', 'idea', 'be', 'time', 'new', 'happened', 'of', 'was', 'began', 'broader', 'treated', 'geometry', 'aspect', 'numbers', 'to', 'move', 'with', 'essentially', 'algebraic', 'and', 'vehicle', 'irrational', 'before', 'namely', 'path', 'geometrical', 'perhaps', 'important', 'whole', 'theory', 'is', 'greek', 'introduction', 'from', 'which', 'way', 'subject', 'it'}\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text_p)\n",
    "print(\"The number of tokens is\", len(words))\n",
    "#some stats\n",
    "average_tokens = round(len(words)/len(sents))\n",
    "print(\"\\n The average number of tokens per sentence is\",average_tokens)\n",
    "\n",
    "unique_tokens = set(words)\n",
    "print(\"\\n The number of unique tokens are\", len(unique_tokens))\n",
    "\n",
    "print('\\n Words:', words)\n",
    "print('\\n Unique Words:',unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total tokens after removing stopwords are 67\n",
      "\n",
      "Filtered words: ['perhaps', 'one', 'significant', 'advances', 'made', 'arabic', 'mathematics', 'began', 'time', 'work', 'alkhwarizmi', 'namely', 'beginnings', 'algebra', 'important', 'understand', 'significant', 'new', 'idea', 'revolutionary', 'move', 'away', 'greek', 'concept', 'mathematics', 'essentially', 'geometry', 'algebra', 'unifying', 'theory', 'allowed', 'rational', 'numbers', 'irrational', 'numbers', 'geometrical', 'magnitudes', 'etc', 'treated', 'algebraic', 'objects', 'gave', 'mathematics', 'whole', 'new', 'development', 'path', 'much', 'broader', 'concept', 'existed', 'provided', 'vehicle', 'future', 'development', 'subject', 'another', 'important', 'aspect', 'introduction', 'algebraic', 'ideas', 'allowed', 'mathematics', 'applied', 'way', 'happened']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(\"The number of total tokens after removing stopwords are\", len((filtered_words)))\n",
    "print('\\nFiltered words:', filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemminf=>Lemmatization=>Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********Tokens + Stemmed words + lemmas:**********\n",
      "\n",
      "perhaps : perhap : perhaps\n",
      "one : one : one\n",
      "significant : signific : significant\n",
      "advances : advanc : advance\n",
      "made : made : made\n",
      "arabic : arab : arabic\n",
      "mathematics : mathemat : mathematics\n",
      "began : began : began\n",
      "time : time : time\n",
      "work : work : work\n",
      "alkhwarizmi : alkhwarizmi : alkhwarizmi\n",
      "namely : name : namely\n",
      "beginnings : begin : beginning\n",
      "algebra : algebra : algebra\n",
      "important : import : important\n",
      "understand : understand : understand\n",
      "significant : signific : significant\n",
      "new : new : new\n",
      "idea : idea : idea\n",
      "revolutionary : revolutionari : revolutionary\n",
      "move : move : move\n",
      "away : away : away\n",
      "greek : greek : greek\n",
      "concept : concept : concept\n",
      "mathematics : mathemat : mathematics\n",
      "essentially : essenti : essentially\n",
      "geometry : geometri : geometry\n",
      "algebra : algebra : algebra\n",
      "unifying : unifi : unifying\n",
      "theory : theori : theory\n",
      "allowed : allow : allowed\n",
      "rational : ration : rational\n",
      "numbers : number : number\n",
      "irrational : irrat : irrational\n",
      "numbers : number : number\n",
      "geometrical : geometr : geometrical\n",
      "magnitudes : magnitud : magnitude\n",
      "etc : etc : etc\n",
      "treated : treat : treated\n",
      "algebraic : algebra : algebraic\n",
      "objects : object : object\n",
      "gave : gave : gave\n",
      "mathematics : mathemat : mathematics\n",
      "whole : whole : whole\n",
      "new : new : new\n",
      "development : develop : development\n",
      "path : path : path\n",
      "much : much : much\n",
      "broader : broader : broader\n",
      "concept : concept : concept\n",
      "existed : exist : existed\n",
      "provided : provid : provided\n",
      "vehicle : vehicl : vehicle\n",
      "future : futur : future\n",
      "development : develop : development\n",
      "subject : subject : subject\n",
      "another : anoth : another\n",
      "important : import : important\n",
      "aspect : aspect : aspect\n",
      "introduction : introduct : introduction\n",
      "algebraic : algebra : algebraic\n",
      "ideas : idea : idea\n",
      "allowed : allow : allowed\n",
      "mathematics : mathemat : mathematics\n",
      "applied : appli : applied\n",
      "way : way : way\n",
      "happened : happen : happened\n",
      "\n",
      "**********Part of Speech:**********\n",
      "\n",
      "perhaps \t:  RB\n",
      "one \t:  CD\n",
      "significant \t:  JJ\n",
      "advances \t:  NNS\n",
      "made \t:  VBN\n",
      "arabic \t:  JJ\n",
      "mathematics \t:  NNS\n",
      "began \t:  VBD\n",
      "time \t:  NN\n",
      "work \t:  NN\n",
      "alkhwarizmi \t:  RB\n",
      "namely \t:  RB\n",
      "beginnings \t:  JJ\n",
      "algebra \t:  NN\n",
      "important \t:  JJ\n",
      "understand \t:  NN\n",
      "significant \t:  JJ\n",
      "new \t:  JJ\n",
      "idea \t:  NN\n",
      "revolutionary \t:  JJ\n",
      "move \t:  VB\n",
      "away \t:  RB\n",
      "greek \t:  JJ\n",
      "concept \t:  NN\n",
      "mathematics \t:  NNS\n",
      "essentially \t:  RB\n",
      "geometry \t:  VBP\n",
      "algebra \t:  JJ\n",
      "unifying \t:  VBG\n",
      "theory \t:  NN\n",
      "allowed \t:  VBN\n",
      "rational \t:  JJ\n",
      "numbers \t:  NNS\n",
      "irrational \t:  JJ\n",
      "numbers \t:  NNS\n",
      "geometrical \t:  JJ\n",
      "magnitudes \t:  NNS\n",
      "etc \t:  VBP\n",
      "treated \t:  VBN\n",
      "algebraic \t:  JJ\n",
      "objects \t:  NNS\n",
      "gave \t:  VBD\n",
      "mathematics \t:  NNS\n",
      "whole \t:  JJ\n",
      "new \t:  JJ\n",
      "development \t:  NN\n",
      "path \t:  NN\n",
      "much \t:  JJ\n",
      "broader \t:  JJR\n",
      "concept \t:  NN\n",
      "existed \t:  VBD\n",
      "provided \t:  JJ\n",
      "vehicle \t:  NN\n",
      "future \t:  NN\n",
      "development \t:  NN\n",
      "subject \t:  NN\n",
      "another \t:  DT\n",
      "important \t:  JJ\n",
      "aspect \t:  NN\n",
      "introduction \t:  NN\n",
      "algebraic \t:  IN\n",
      "ideas \t:  NNS\n",
      "allowed \t:  VBN\n",
      "mathematics \t:  NNS\n",
      "applied \t:  VBD\n",
      "way \t:  NN\n",
      "happened \t:  VBD\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in filtered_words]\n",
    " \n",
    "#Lemmatization    \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "#postagging    \n",
    "pos = pos_tag(filtered_words)\n",
    "\n",
    "#printing results\n",
    "\n",
    "print('\\n**********Tokens + Stemmed words + lemmas:**********\\n')\n",
    "for i in range(len(filtered_words)):\n",
    "    print(filtered_words[i], stemmed[i], lemmatized[i],sep=\" : \")\n",
    "print('\\n**********Part of Speech:**********\\n')\n",
    "for i in range(len(pos)):\n",
    "    print(pos[i][0], \"\\t: \", pos[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
