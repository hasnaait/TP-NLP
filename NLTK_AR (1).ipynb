{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP_NLTK_AR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import  word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import  WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk import StanfordTagger\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي  وهي بدايات الجبر،ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن\n",
    "المفهوم اليوناني للرياضيات التي هي في جوهرها  هندسة، الجبركان نظرية موحدة تتحيح الأعداد الكسرية والأعداد اللا كسرية ، والمقادير الهندسية و غيرها ، أن تتعامل على أنها أجسام جبرية، وأعطت الرياضيات ككل مسارا جديدًا للتطوربمفهوم \n",
    " أوسع بكثير من الذي كان موجودًا من قبل ، وقدم وسيلة للتنمية في هذا الموضوع مستقبلا . وجانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها \n",
    "بطريقة  لم تحدث من قبل.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences is 2\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(text)\n",
    "print(\"The number of sentences is\", len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning from punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = \"\".join([char for char in text if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens is 104\n",
      "\n",
      " The average number of tokens per sentence is 52\n",
      "\n",
      " The number of unique tokens are 88\n",
      "\n",
      " Words: ['ربما', 'كانت', 'أحد', 'أهم', 'التطورات', 'التي', 'قامت', 'بها', 'الرياضيات', 'العربية', 'التي', 'بدأت', 'في', 'هذا', 'الوقت', 'بعمل', 'الخوارزمي', 'وهي', 'بدايات', 'الجبر،ومن', 'المهم', 'فهم', 'كيف', 'كانت', 'هذه', 'الفكرة', 'الجديدة', 'مهمة،', 'فقد', 'كانت', 'خطوة', 'ثورية', 'بعيدا', 'عن', 'المفهوم', 'اليوناني', 'للرياضيات', 'التي', 'هي', 'في', 'جوهرها', 'هندسة،', 'الجبركان', 'نظرية', 'موحدة', 'تتحيح', 'الأعداد', 'الكسرية', 'والأعداد', 'اللا', 'كسرية', '،', 'والمقادير', 'الهندسية', 'و', 'غيرها', '،', 'أن', 'تتعامل', 'على', 'أنها', 'أجسام', 'جبرية،', 'وأعطت', 'الرياضيات', 'ككل', 'مسارا', 'جديدًا', 'للتطوربمفهوم', 'أوسع', 'بكثير', 'من', 'الذي', 'كان', 'موجودًا', 'من', 'قبل', '،', 'وقدم', 'وسيلة', 'للتنمية', 'في', 'هذا', 'الموضوع', 'مستقبلا', 'وجانب', 'آخر', 'مهم', 'لإدخال', 'أفكار', 'الجبر', 'و', 'هو', 'أنه', 'سمح', 'بتطبيق', 'الرياضيات', 'على', 'نفسها', 'بطريقة', 'لم', 'تحدث', 'من', 'قبل']\n",
      "\n",
      " Unique Words: {'المفهوم', 'وسيلة', 'وقدم', 'فقد', 'والأعداد', 'قبل', 'قامت', 'و', 'فهم', 'تتعامل', 'كانت', 'كيف', 'لإدخال', 'التطورات', 'جوهرها', 'العربية', 'تتحيح', 'الذي', 'بدأت', 'الوقت', 'بعيدا', '،', 'الهندسية', 'تحدث', 'مهم', 'بتطبيق', 'غيرها', 'موحدة', 'مستقبلا', 'التي', 'في', 'وأعطت', 'كسرية', 'ربما', 'جبرية،', 'بطريقة', 'بها', 'الجبركان', 'أنها', 'موجودًا', 'للتطوربمفهوم', 'أحد', 'بدايات', 'هذا', 'نفسها', 'عن', 'للتنمية', 'هو', 'جديدًا', 'وهي', 'للرياضيات', 'على', 'وجانب', 'ثورية', 'من', 'والمقادير', 'الجبر،ومن', 'اللا', 'كان', 'لم', 'الفكرة', 'سمح', 'الأعداد', 'خطوة', 'مهمة،', 'مسارا', 'الجديدة', 'الرياضيات', 'الجبر', 'اليوناني', 'هذه', 'الكسرية', 'الموضوع', 'أن', 'أجسام', 'أوسع', 'أنه', 'بكثير', 'الخوارزمي', 'نظرية', 'المهم', 'آخر', 'أفكار', 'أهم', 'بعمل', 'هي', 'هندسة،', 'ككل'}\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text_p)\n",
    "print(\"The number of tokens is\", len(words))\n",
    "#some stats\n",
    "average_tokens = round(len(words)/len(sents))\n",
    "print(\"\\n The average number of tokens per sentence is\",average_tokens)\n",
    "\n",
    "unique_tokens = set(words)\n",
    "print(\"\\n The number of unique tokens are\", len(unique_tokens))\n",
    "\n",
    "print('\\n Words:', words)\n",
    "print('\\n Unique Words:',unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total tokens after removing stopwords are 82\n",
      "\n",
      "Filtered words: ['ربما', 'كانت', 'أحد', 'أهم', 'التطورات', 'قامت', 'الرياضيات', 'العربية', 'بدأت', 'الوقت', 'بعمل', 'الخوارزمي', 'وهي', 'بدايات', 'الجبر،ومن', 'المهم', 'فهم', 'كانت', 'الفكرة', 'الجديدة', 'مهمة،', 'فقد', 'كانت', 'خطوة', 'ثورية', 'بعيدا', 'المفهوم', 'اليوناني', 'للرياضيات', 'جوهرها', 'هندسة،', 'الجبركان', 'نظرية', 'موحدة', 'تتحيح', 'الأعداد', 'الكسرية', 'والأعداد', 'اللا', 'كسرية', '،', 'والمقادير', 'الهندسية', 'و', 'غيرها', '،', 'تتعامل', 'أنها', 'أجسام', 'جبرية،', 'وأعطت', 'الرياضيات', 'ككل', 'مسارا', 'جديدًا', 'للتطوربمفهوم', 'أوسع', 'بكثير', 'كان', 'موجودًا', 'قبل', '،', 'وقدم', 'وسيلة', 'للتنمية', 'الموضوع', 'مستقبلا', 'وجانب', 'آخر', 'مهم', 'لإدخال', 'أفكار', 'الجبر', 'و', 'أنه', 'سمح', 'بتطبيق', 'الرياضيات', 'نفسها', 'بطريقة', 'تحدث', 'قبل']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('arabic')\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(\"The number of total tokens after removing stopwords are\", len((filtered_words)))\n",
    "print('\\nFiltered words:', filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming=>Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********Tokens + Stemmed words + lemmas:**********\n",
      "\n",
      "ربما : ربم\n",
      "كانت : كانت\n",
      "أحد : احد\n",
      "أهم : اهم\n",
      "التطورات : تطر\n",
      "قامت : قمت\n",
      "الرياضيات : ريض\n",
      "العربية : عرب\n",
      "بدأت : بدأ\n",
      "الوقت : وقت\n",
      "بعمل : عمل\n",
      "الخوارزمي : خوارزم\n",
      "وهي : وهي\n",
      "بدايات : بدي\n",
      "الجبر،ومن : جبر،وم\n",
      "المهم : مهم\n",
      "فهم : فهم\n",
      "كانت : كانت\n",
      "الفكرة : فكر\n",
      "الجديدة : جدد\n",
      "مهمة، : همة،\n",
      "فقد : فقد\n",
      "كانت : كانت\n",
      "خطوة : خطة\n",
      "ثورية : ثور\n",
      "بعيدا : بعد\n",
      "المفهوم : فهم\n",
      "اليوناني : يون\n",
      "للرياضيات : ريض\n",
      "جوهرها : جوهر\n",
      "هندسة، : هندسة،\n",
      "الجبركان : جبر\n",
      "نظرية : نظر\n",
      "موحدة : وحد\n",
      "تتحيح : تحح\n",
      "الأعداد : عدد\n",
      "الكسرية : كسر\n",
      "والأعداد : عدد\n",
      "اللا : الل\n",
      "كسرية : كسر\n",
      "، : ،\n",
      "والمقادير : مقادير\n",
      "الهندسية : هندس\n",
      "و : و\n",
      "غيرها : غير\n",
      "، : ،\n",
      "تتعامل : عمل\n",
      "أنها : انه\n",
      "أجسام : جسم\n",
      "جبرية، : جبرية،\n",
      "وأعطت : أعط\n",
      "الرياضيات : ريض\n",
      "ككل : ككل\n",
      "مسارا : سرا\n",
      "جديدًا : جدد\n",
      "للتطوربمفهوم : تطوربمفهوم\n",
      "أوسع : وسع\n",
      "بكثير : كثر\n",
      "كان : كان\n",
      "موجودًا : وجد\n",
      "قبل : قبل\n",
      "، : ،\n",
      "وقدم : قدم\n",
      "وسيلة : وسل\n",
      "للتنمية : نمي\n",
      "الموضوع : وضع\n",
      "مستقبلا : قبل\n",
      "وجانب : جنب\n",
      "آخر : اخر\n",
      "مهم : مهم\n",
      "لإدخال : إدخال\n",
      "أفكار : فكر\n",
      "الجبر : جبر\n",
      "و : و\n",
      "أنه : انه\n",
      "سمح : سمح\n",
      "بتطبيق : طبق\n",
      "الرياضيات : ريض\n",
      "نفسها : نفس\n",
      "بطريقة : طرق\n",
      "تحدث : حدث\n",
      "قبل : قبل\n",
      "\n",
      "**********Part of Speech:**********\n",
      "\n",
      "ربما \t:  JJ\n",
      "كانت \t:  NNP\n",
      "أحد \t:  NNP\n",
      "أهم \t:  NNP\n",
      "التطورات \t:  NNP\n",
      "قامت \t:  NNP\n",
      "الرياضيات \t:  NNP\n",
      "العربية \t:  NNP\n",
      "بدأت \t:  NNP\n",
      "الوقت \t:  NNP\n",
      "بعمل \t:  NNP\n",
      "الخوارزمي \t:  NNP\n",
      "وهي \t:  NNP\n",
      "بدايات \t:  NNP\n",
      "الجبر،ومن \t:  NNP\n",
      "المهم \t:  NNP\n",
      "فهم \t:  NNP\n",
      "كانت \t:  NNP\n",
      "الفكرة \t:  NNP\n",
      "الجديدة \t:  NNP\n",
      "مهمة، \t:  NNP\n",
      "فقد \t:  NNP\n",
      "كانت \t:  NNP\n",
      "خطوة \t:  NNP\n",
      "ثورية \t:  NNP\n",
      "بعيدا \t:  NNP\n",
      "المفهوم \t:  NNP\n",
      "اليوناني \t:  NNP\n",
      "للرياضيات \t:  NNP\n",
      "جوهرها \t:  NNP\n",
      "هندسة، \t:  NNP\n",
      "الجبركان \t:  NNP\n",
      "نظرية \t:  NNP\n",
      "موحدة \t:  NNP\n",
      "تتحيح \t:  NNP\n",
      "الأعداد \t:  NNP\n",
      "الكسرية \t:  NNP\n",
      "والأعداد \t:  NNP\n",
      "اللا \t:  NNP\n",
      "كسرية \t:  NNP\n",
      "، \t:  NNP\n",
      "والمقادير \t:  NNP\n",
      "الهندسية \t:  NNP\n",
      "و \t:  NNP\n",
      "غيرها \t:  NNP\n",
      "، \t:  NNP\n",
      "تتعامل \t:  NNP\n",
      "أنها \t:  NNP\n",
      "أجسام \t:  NNP\n",
      "جبرية، \t:  NNP\n",
      "وأعطت \t:  NNP\n",
      "الرياضيات \t:  NNP\n",
      "ككل \t:  NNP\n",
      "مسارا \t:  NNP\n",
      "جديدًا \t:  NNP\n",
      "للتطوربمفهوم \t:  NNP\n",
      "أوسع \t:  NNP\n",
      "بكثير \t:  NNP\n",
      "كان \t:  NNP\n",
      "موجودًا \t:  NNP\n",
      "قبل \t:  NNP\n",
      "، \t:  NNP\n",
      "وقدم \t:  NNP\n",
      "وسيلة \t:  NNP\n",
      "للتنمية \t:  NNP\n",
      "الموضوع \t:  NNP\n",
      "مستقبلا \t:  NNP\n",
      "وجانب \t:  NNP\n",
      "آخر \t:  NNP\n",
      "مهم \t:  NNP\n",
      "لإدخال \t:  NNP\n",
      "أفكار \t:  NNP\n",
      "الجبر \t:  NNP\n",
      "و \t:  NNP\n",
      "أنه \t:  NNP\n",
      "سمح \t:  NNP\n",
      "بتطبيق \t:  NNP\n",
      "الرياضيات \t:  NNP\n",
      "نفسها \t:  NNP\n",
      "بطريقة \t:  NNP\n",
      "تحدث \t:  NNP\n",
      "قبل \t:  NN\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "iris = ISRIStemmer()\n",
    "stemmed = [iris.stem(word) for word in filtered_words]\n",
    " \n",
    "\n",
    "#postagging    \n",
    "pos = pos_tag(filtered_words)\n",
    "\n",
    "#printing results\n",
    "\n",
    "print('\\n**********Tokens + Stemmed words + lemmas:**********\\n')\n",
    "for i in range(len(filtered_words)):\n",
    "    print(filtered_words[i], stemmed[i],sep=\" : \")\n",
    "print('\\n**********Part of Speech:**********\\n')\n",
    "for i in range(len(pos)):\n",
    "    print(pos[i][0], \"\\t: \", pos[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
